<!DOCTYPE html>
<html>
<head>
    <title>Nod.ie Browser Test</title>
    <style>
        body {
            font-family: monospace;
            padding: 20px;
            background: #1a1a1a;
            color: #0f0;
        }
        button {
            padding: 10px 20px;
            margin: 10px;
            cursor: pointer;
            background: #333;
            color: #0f0;
            border: 1px solid #0f0;
        }
        button:hover {
            background: #444;
        }
        #status {
            padding: 20px;
            background: #000;
            border: 1px solid #0f0;
            margin: 20px 0;
            min-height: 100px;
        }
        #logs {
            padding: 20px;
            background: #000;
            border: 1px solid #0f0;
            height: 400px;
            overflow-y: auto;
            white-space: pre-wrap;
        }
        .error { color: #f00; }
        .success { color: #0f0; }
        .info { color: #0ff; }
        .warning { color: #ff0; }
        .audio { color: #f0f; }
        #comparison {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-top: 20px;
        }
        .panel {
            background: #000;
            border: 1px solid #0f0;
            padding: 10px;
        }
    </style>
</head>
<body>
    <h1>ðŸŽ¤ Nod.ie Browser Test</h1>
    
    <div id="status">
        <div>Status: <span id="statusText">Not connected</span></div>
        <div>Audio Context: <span id="audioContextState">-</span></div>
        <div>Microphone: <span id="micState">-</span></div>
        <div>WebSocket: <span id="wsState">-</span></div>
    </div>

    <div>
        <button onclick="startNodie()">Start Nod.ie Implementation</button>
        <button onclick="startUnmute()">Start Unmute Implementation</button>
        <button onclick="compareImplementations()">Compare Both</button>
        <button onclick="clearLogs()">Clear Logs</button>
        <button onclick="stopAll()">Stop All</button>
    </div>

    <div id="comparison">
        <div class="panel">
            <h3>Nod.ie Implementation</h3>
            <div id="nodieInfo">-</div>
        </div>
        <div class="panel">
            <h3>Unmute Implementation</h3>
            <div id="unmuteInfo">-</div>
        </div>
    </div>

    <h3>Logs:</h3>
    <div id="logs"></div>

    <!-- Load opus-recorder for Nod.ie implementation -->
    <script src="../node_modules/opus-recorder/dist/recorder.min.js"></script>
    <script src="../node_modules/opus-recorder/dist/encoderWorker.min.js"></script>
    <script src="../decoderWorker.min.js"></script>

    <script>
        let ws = null;
        let recorder = null;
        let audioContext = null;
        let audioPlayback = null;
        let implementation = null;

        // Enhanced logging
        function log(message, type = 'info') {
            const timestamp = new Date().toISOString().substr(11, 12);
            const logDiv = document.getElementById('logs');
            const entry = document.createElement('div');
            entry.className = type;
            entry.textContent = `[${timestamp}] ${message}`;
            logDiv.appendChild(entry);
            logDiv.scrollTop = logDiv.scrollHeight;
            console.log(`[${type}]`, message);
        }

        // Update status display
        function updateStatus() {
            document.getElementById('audioContextState').textContent = 
                audioContext ? audioContext.state : 'Not created';
            document.getElementById('micState').textContent = 
                recorder ? 'Active' : 'Inactive';
            document.getElementById('wsState').textContent = 
                ws ? `${ws.readyState} (${ws.url})` : 'Not connected';
        }

        // Nod.ie implementation (matching renderer.js)
        async function startNodie() {
            log('Starting Nod.ie implementation...', 'info');
            implementation = 'nodie';
            document.getElementById('statusText').textContent = 'Starting Nod.ie...';

            try {
                // Initialize audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                log(`Audio context created: sampleRate=${audioContext.sampleRate}`, 'success');

                // Get microphone
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: false,
                        autoGainControl: true,
                        channelCount: 1
                    }
                });
                log('Microphone access granted', 'success');

                // Setup opus-recorder (matching audio-capture.js)
                const recorderOptions = {
                    mediaTrackConstraints: {
                        audio: {
                            echoCancellation: true,
                            noiseSuppression: false,
                            autoGainControl: true,
                            channelCount: 1
                        }
                    },
                    encoderPath: '../node_modules/opus-recorder/dist/encoderWorker.min.js',
                    bufferLength: Math.round((960 * audioContext.sampleRate) / 24000),
                    encoderFrameSize: 20,
                    encoderSampleRate: 24000,
                    maxFramesPerPage: 2,
                    numberOfChannels: 1,
                    recordingGain: 1,
                    resampleQuality: 3,
                    encoderComplexity: 0,
                    encoderApplication: 2049,
                    streamPages: true
                };

                log(`Recorder options: ${JSON.stringify(recorderOptions, null, 2)}`, 'info');

                recorder = new Recorder(recorderOptions);
                let chunkCount = 0;

                recorder.ondataavailable = (data) => {
                    chunkCount++;
                    
                    // Log first few chunks for debugging
                    if (chunkCount <= 3) {
                        log(`Audio chunk ${chunkCount}: size=${data.length}, first 4 bytes=[${Array.from(data.slice(0, 4))}]`, 'audio');
                        
                        // Check OGG header
                        const header = String.fromCharCode(...data.slice(0, 4));
                        log(`OGG header: "${header}" (expected "OggS")`, header === 'OggS' ? 'success' : 'error');
                    }

                    // Base64 encode
                    let binary = "";
                    for (let i = 0; i < data.length; i++) {
                        binary += String.fromCharCode(data[i]);
                    }
                    const base64 = btoa(binary);

                    // Send to WebSocket
                    if (ws && ws.readyState === WebSocket.OPEN) {
                        const message = {
                            type: 'input_audio_buffer.append',
                            audio: base64
                        };
                        ws.send(JSON.stringify(message));
                        
                        if (chunkCount <= 3) {
                            log(`Sent audio message: ${JSON.stringify(message).substring(0, 100)}...`, 'audio');
                        }
                    }
                };

                // Connect WebSocket
                connectWebSocket();

                // Start recording
                await audioContext.resume();
                await recorder.start();
                log('Recording started', 'success');
                document.getElementById('statusText').textContent = 'Nod.ie running';

                updateStatus();

            } catch (error) {
                log(`Error: ${error.message}`, 'error');
                console.error(error);
            }
        }

        // Unmute reference implementation
        async function startUnmute() {
            log('Opening Unmute frontend for comparison...', 'info');
            window.open('http://localhost:3000', '_blank');
            log('Please check the Unmute frontend and compare the network traffic', 'warning');
        }

        // WebSocket connection
        function connectWebSocket() {
            const wsUrl = 'ws://localhost:8765/v1/realtime';
            log(`Connecting to ${wsUrl}...`, 'info');

            ws = new WebSocket(wsUrl, ['realtime']);
            let messageCount = 0;

            ws.onopen = () => {
                log('WebSocket connected', 'success');
                
                // Send session configuration
                const sessionConfig = {
                    type: 'session.update',
                    session: {
                        voice: 'nova',
                        language: 'en',
                        output_audio_format: 'opus',
                        instructions: {
                            type: 'constant',
                            text: 'You are Nod.ie, a helpful AI assistant. Keep responses brief.'
                        }
                    }
                };
                
                log(`Sending session config: ${JSON.stringify(sessionConfig, null, 2)}`, 'info');
                ws.send(JSON.stringify(sessionConfig));
                updateStatus();
            };

            ws.onmessage = async (event) => {
                messageCount++;
                const data = JSON.parse(event.data);
                
                // Log all message types
                if (messageCount <= 10 || data.type.includes('error')) {
                    log(`Message ${messageCount}: type=${data.type}`, 'info');
                }

                // Handle different message types
                switch(data.type) {
                    case 'error':
                        log(`Error: ${JSON.stringify(data.error)}`, 'error');
                        break;
                        
                    case 'response.audio.delta':
                        if (data.delta) {
                            log(`Audio delta received: ${data.delta.substring(0, 50)}...`, 'audio');
                            await playAudioDelta(data.delta);
                        }
                        break;
                        
                    case 'response.audio_transcript.delta':
                        if (data.delta) {
                            log(`Transcript: ${data.delta}`, 'success');
                        }
                        break;
                        
                    case 'conversation.item.input_audio_transcription.delta':
                        if (data.transcript) {
                            log(`You said: ${data.transcript}`, 'info');
                        }
                        break;
                        
                    case 'response.created':
                        log('Response created - AI is thinking...', 'warning');
                        break;
                        
                    case 'response.done':
                        log('Response complete', 'success');
                        break;
                }
            };

            ws.onerror = (error) => {
                log(`WebSocket error: ${error}`, 'error');
                updateStatus();
            };

            ws.onclose = (event) => {
                log(`WebSocket closed: code=${event.code}, reason=${event.reason}`, 'warning');
                updateStatus();
            };
        }

        // Audio playback (simplified from audio-playback.js)
        async function playAudioDelta(base64Audio) {
            if (!audioPlayback) {
                log('Initializing audio playback...', 'info');
                
                // Create audio context if needed
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }

                // Try to decode the audio
                try {
                    // Decode base64
                    const binaryString = atob(base64Audio);
                    const bytes = new Uint8Array(binaryString.length);
                    for (let i = 0; i < binaryString.length; i++) {
                        bytes[i] = binaryString.charCodeAt(i);
                    }
                    
                    log(`Attempting to decode audio: ${bytes.length} bytes`, 'audio');
                    
                    // Try direct decoding first
                    const audioBuffer = await audioContext.decodeAudioData(bytes.buffer);
                    
                    // Play it
                    const source = audioContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(audioContext.destination);
                    source.start();
                    
                    log('Audio played successfully!', 'success');
                    
                } catch (decodeError) {
                    log(`Direct decode failed: ${decodeError.message}`, 'error');
                    log('This is expected - Unmute sends Opus frames that need special decoding', 'warning');
                    
                    // This is where we need the Opus decoder worker
                    // For now, just log what we received
                    log(`Base64 audio sample: ${base64Audio.substring(0, 100)}...`, 'audio');
                }
            }
        }

        // Compare implementations
        async function compareImplementations() {
            log('=== COMPARING IMPLEMENTATIONS ===', 'info');
            
            // Nod.ie info
            const nodieInfo = `
Audio Format: Opus in OGG container
Encoder: opus-recorder with streamPages
Sample Rate: 24000 Hz
Channels: 1
Frame Size: 20ms
WebSocket: ${ws ? 'Connected' : 'Not connected'}
            `;
            
            // Unmute info
            const unmuteInfo = `
Audio Format: Opus in OGG container
Encoder: opus-recorder with streamPages
Sample Rate: 24000 Hz  
Channels: 1
Frame Size: 20ms
WebSocket: Connected (check Network tab)
            `;
            
            document.getElementById('nodieInfo').textContent = nodieInfo;
            document.getElementById('unmuteInfo').textContent = unmuteInfo;
            
            // Log key differences
            log('Key areas to check:', 'warning');
            log('1. Network tab: Compare WebSocket messages', 'info');
            log('2. Audio format: Both should send OggS headers', 'info');
            log('3. Message structure: Check input_audio_buffer.append format', 'info');
            log('4. Response handling: Check response.audio.delta processing', 'info');
            
            // Capture backend logs
            log('Fetching backend logs...', 'info');
            try {
                const response = await fetch('/api/backend-logs');
                const logs = await response.text();
                log(`Backend logs: ${logs.substring(0, 200)}...`, 'info');
            } catch (e) {
                log('Cannot fetch backend logs from browser', 'warning');
            }
        }

        function clearLogs() {
            document.getElementById('logs').innerHTML = '';
            log('Logs cleared', 'info');
        }

        function stopAll() {
            if (recorder) {
                recorder.stop();
                recorder = null;
                log('Recording stopped', 'info');
            }
            if (ws) {
                ws.close();
                ws = null;
                log('WebSocket closed', 'info');
            }
            if (audioContext) {
                audioContext.close();
                audioContext = null;
                log('Audio context closed', 'info');
            }
            document.getElementById('statusText').textContent = 'Stopped';
            updateStatus();
        }

        // Update status every second
        setInterval(updateStatus, 1000);
    </script>
</body>
</html>